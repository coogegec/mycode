{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "# 필드 목록 정의\n",
    "# 비정형 필드\n",
    "title_arr=[]\n",
    "# 분류값을 저장할 배열 (0,1)\n",
    "ctr_arr=[]\n",
    "# 텍스트와 분류값이 저장된 파일 불러오기 (학습용 데이터셋)\n",
    "f=open('d:/data/text/ratings_train.csv', encoding='ms949')\n",
    "reader=csv.reader(f)\n",
    "max_length, length, max_idx, count, count_train=0,0,0,0,0\n",
    "next(reader, None) # 헤더 스킵(첫 라인을 건너뜀)\n",
    "for line in reader:\n",
    "    # 레코드 전체를 하는 방법\n",
    "    title_arr.append(line[0]) # 텍스트 필드\n",
    "    ctr_arr.append(int(line[1])) # 결과 필드\n",
    "    length=len(line[0]) # 텍스트의 길이\n",
    "    if max_length<length:\n",
    "        max_length=length\n",
    "        max_idx=count\n",
    "    count+=1\n",
    "    count_train+=1\n",
    "    if count_train>=10000:\n",
    "        break\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트와 분류값이 저장된 파일 불러오기 (검증용 데이터셋)\n",
    "f2=open('d:/data/text/ratings_test.csv', 'r', encoding='ms949')\n",
    "reader=csv.reader(f2)\n",
    "next(reader, None) # 헤더 스킵(첫 라인을 건너뜀)\n",
    "count_test=0\n",
    "for line in reader:\n",
    "    # 레코드 전체를 하는 방법\n",
    "    title_arr.append(line[0]) # 텍스트 필드\n",
    "    ctr_arr.append(int(line[1])) # 결과 필드\n",
    "    length=len(line[0]) # 텍스트의 길이\n",
    "    if max_length<length:\n",
    "        max_length=length\n",
    "        max_idx=count\n",
    "    count+=1\n",
    "    count_test+=1\n",
    "    if count_test>=10000:\n",
    "        break\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_train : 10000\n",
      "count_test : 10000\n",
      "title_arr size : 20000\n",
      "ctr_arr size : 20000\n",
      "max_length : 144\n"
     ]
    }
   ],
   "source": [
    "print('count_train :', count_train)\n",
    "print('count_test :', count_test)\n",
    "print('title_arr size :', len(title_arr))\n",
    "print('ctr_arr size :', len(ctr_arr))\n",
    "print('max_length :', max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0\n",
      "step : 1000\n",
      "step : 2000\n",
      "step : 3000\n",
      "step : 4000\n",
      "step : 5000\n",
      "step : 6000\n",
      "step : 7000\n",
      "step : 8000\n",
      "step : 9000\n",
      "step : 10000\n",
      "step : 11000\n",
      "step : 12000\n",
      "step : 13000\n",
      "step : 14000\n",
      "step : 15000\n",
      "step : 16000\n",
      "step : 17000\n",
      "step : 18000\n",
      "step : 19000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt=Okt()\n",
    "# 명사(Noun), 형용사(Adjective), 동사(Verb), 알파벳(Alpha), 부사(Adverb)\n",
    "title_noun_arr=[]\n",
    "for index, title in enumerate(title_arr):\n",
    "    if index%1000==0:\n",
    "        print('step :', index)\n",
    "    title_noun_arr.append(okt.nouns(title)) # 명사만 추출\n",
    "print(len(title_noun_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0\n",
      "step : 10000\n"
     ]
    }
   ],
   "source": [
    "# 벡터 모델을 불러와서 텍스트를 벡터로 변환\n",
    "import gensim\n",
    "\n",
    "MIN_NOUN_VECTOR_VALUE=-10.0\n",
    "MAX_NOUN_VECTOR_VALUE=10.0\n",
    "NOUN_VECTOR_SIZE=100\n",
    "# 벡터 생성 함수\n",
    "def generate_random_noun_vector():\n",
    "    return np.random.uniform(low=MIN_NOUN_VECTOR_VALUE, high=MAX_NOUN_VECTOR_VALUE, size=(NOUN_VECTOR_SIZE,))\n",
    "# word2vec 모델 불러오기\n",
    "w2v_model=gensim.models.Word2Vec.load('d:/data/text/text_100.model')\n",
    "title_noun_vector_arr=[] # 벡터를 저장할 리스트\n",
    "for index, title_nouns in enumerate(title_noun_arr):\n",
    "    if index%10000==0:\n",
    "        print('step :', index)\n",
    "    noun_vector_arr=[]\n",
    "    for noun in title_nouns:\n",
    "        try:\n",
    "            noun_vector=w2v_model[noun] # 단어별로 벡터 모델 적용\n",
    "        except Exception as e:\n",
    "            noun_vector=generate_random_noun_vector() # 단어사전에 존재하지 않으면 기본 벡터 생성\n",
    "        noun_vector_arr.append(noun_vector)\n",
    "    title_noun_vector_arr.append(noun_vector_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([ 7.00788343,  2.32315639, -1.40969122, -3.84805147,  3.29545899,\n",
      "       -8.90883713,  9.01968983,  1.03392477, -4.94896253, -7.80244264,\n",
      "       -6.87449978, -3.40472584, -2.65472253,  5.5133203 , -7.62624073,\n",
      "        3.47444128,  3.79038021, -5.81187471,  8.77789576, -6.74079621,\n",
      "       -2.83244624,  2.73309272,  1.82372676,  0.59821992,  9.11019838,\n",
      "       -9.69831764,  5.11724656, -3.92678061,  3.13228975,  7.15997391,\n",
      "        6.67341528, -3.38749637, -0.682627  ,  9.68549935, -7.33099522,\n",
      "       -2.73028487, -5.32240615, -3.40690896, -9.60176702, -2.66634534,\n",
      "        3.87404446, -3.53657815, -7.68443187, -7.57807797,  8.42360889,\n",
      "        6.64454624,  1.33169172,  0.62125047,  0.35773496, -8.7316495 ,\n",
      "        6.2310939 , -6.65445085,  3.19792357, -1.51205631, -6.66298008,\n",
      "       -1.05532875,  1.17327262,  8.17806174,  3.84374824,  3.53025782,\n",
      "       -1.48479069,  0.04184469,  0.90103294,  4.83027947, -9.73185307,\n",
      "       -4.87778227, -6.63978699,  3.41341984,  6.3359605 ,  0.36682892,\n",
      "        1.83154011,  6.28265906,  2.68111724,  2.71344571,  1.74960775,\n",
      "       -4.84342653,  0.66731418,  4.31910933, -5.58437182,  8.64341234,\n",
      "       -2.10805198,  7.59151024,  4.55890796, -1.49800296, -2.30688466,\n",
      "        2.61396124, -4.39788804,  1.68286819, -3.22575173,  4.56549559,\n",
      "        7.59803469,  2.14548843,  0.92143793, -9.36643556, -5.51622765,\n",
      "        3.43056034, -3.83784259,  7.08799643,  4.40431058,  5.9102613 ]), array([-3.8591617 , -1.89543132, -7.94118398, -9.35673624,  1.03687608,\n",
      "        5.47571738,  4.05755875, -9.95095486,  5.38006263, -0.59185308,\n",
      "        7.93323573,  5.03074513,  8.89587996,  0.6375403 , -5.14041015,\n",
      "        0.93889036, -4.12196303, -0.21079109, -6.82953729,  5.56717886,\n",
      "        1.22250737, -0.18065967,  3.63757323,  0.13932317,  7.99721311,\n",
      "       -7.00758476,  0.94956202,  4.02468017,  8.92118342, -2.95895487,\n",
      "       -9.31097331,  5.61492425,  7.92816799, -5.35169753, -0.46038246,\n",
      "        7.99541643, -4.20787885,  1.64533215, -6.23365504,  9.0960285 ,\n",
      "       -6.90262308,  7.76922654,  8.28500894, -6.24598512,  6.51599645,\n",
      "       -1.40491254, -9.72783674, -4.94682926, -5.13052376,  6.67423109,\n",
      "       -1.85889909,  8.296489  , -7.32727949,  2.96042218,  1.98564597,\n",
      "       -6.00902963, -5.15433176,  3.32464113,  8.00076418,  7.35480154,\n",
      "       -3.33853441, -2.74015228, -2.03541996,  2.39764823,  3.15914108,\n",
      "        3.93073447,  9.58245825,  3.85247781,  0.62766145, -5.2403046 ,\n",
      "       -3.28729361,  4.06920419,  6.48006115, -1.57026363,  9.52157949,\n",
      "       -8.64515484,  1.76436558, -9.59923635,  8.62221785, -1.72411454,\n",
      "        2.02134681,  3.03013283, -1.56339308,  6.21948384,  3.00127888,\n",
      "        7.38328468,  1.0385497 ,  4.60932546, -4.44742587,  6.86238472,\n",
      "       -4.03020175,  2.21785191, -7.52906436,  9.48990781, -6.98275837,\n",
      "       -9.20845902,  4.10899777,  9.86875908, -2.5082584 ,  7.16184557]), array([-4.30012986,  2.69548406,  4.08433734,  6.06682769, -1.5139061 ,\n",
      "       -2.22503811, -6.93510356,  4.64582219, -5.85138821, -7.87083024,\n",
      "       -3.80270888,  8.61519042,  6.72030285, -7.78300521, -2.94551777,\n",
      "        3.47127853, -8.85471039, -8.21633207, -9.14982638,  1.40502416,\n",
      "       -0.48572411,  1.40860619, -2.88613919, -0.90953427, -8.43367657,\n",
      "        6.38375165, -6.17149075,  2.81674597,  5.03019157,  3.06392903,\n",
      "       -7.38236301,  8.56038111, -2.63048923,  6.03972873, -7.24458075,\n",
      "        6.54561043,  9.69887716,  9.26744142, -2.39865433, -8.80312225,\n",
      "       -3.04232714,  0.62254546, -1.44024921, -2.74298953,  7.62688666,\n",
      "        1.04117387,  9.03265145, -4.05444219, -0.3789824 ,  3.26307588,\n",
      "       -2.09374761,  7.88208293, -1.61478025,  0.61545837, -6.5123195 ,\n",
      "       -3.06927805, -8.65584554, -3.08796579,  1.54689019, -4.71045255,\n",
      "       -8.06056518,  0.11945877, -7.64173678,  6.54091679, -5.07948714,\n",
      "        7.49560582, -3.15805415, -7.9727001 , -6.7121114 , -3.70573496,\n",
      "        8.10201817,  9.88732202, -1.50369287, -8.55841168, -5.52327703,\n",
      "       -0.37081458,  2.30522806,  0.10289211,  8.95252436, -1.36751652,\n",
      "       -0.07423806,  6.48364329, -7.79061453,  7.40100058,  1.96106681,\n",
      "       -7.8909725 ,  0.13409319, -6.75751897,  9.18431395, -6.84769545,\n",
      "        7.17216338,  8.30817312, -8.1210115 , -2.85084265,  4.74149659,\n",
      "        1.37741934,  9.77579337,  9.72631283, -3.2352568 ,  5.52052423])]]\n"
     ]
    }
   ],
   "source": [
    "print(title_noun_vector_arr[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0\n",
      "step : 1000\n",
      "step : 2000\n",
      "step : 3000\n",
      "step : 4000\n",
      "step : 5000\n",
      "step : 6000\n",
      "step : 7000\n",
      "step : 8000\n",
      "step : 9000\n",
      "step : 10000\n",
      "step : 11000\n",
      "step : 12000\n",
      "step : 13000\n",
      "step : 14000\n",
      "step : 15000\n",
      "step : 16000\n",
      "step : 17000\n",
      "step : 18000\n",
      "step : 19000\n"
     ]
    }
   ],
   "source": [
    "max_size, min_size, avg, count, sum_size=0,100,0,0,0\n",
    "# 가장 긴 리뷰 텍스트 계산\n",
    "for index, title_noun_vector in enumerate(title_noun_vector_arr):\n",
    "    if len(title_noun_vector)==0:\n",
    "        pass\n",
    "    sum_size+=len(title_noun_vector)\n",
    "    if max_size<len(title_noun_vector):\n",
    "        max_size=len(title_noun_vector)\n",
    "    if min_size>len(title_noun_vector):\n",
    "        min_size=len(title_noun_vector)\n",
    "    count+=1\n",
    "\n",
    "TITLE_LENGTH=max_size\n",
    "\n",
    "def generate_zero_noun_vector():\n",
    "    return np.random.uniform(low=0.0, high=0.0, size=(NOUN_VECTOR_SIZE,))\n",
    "\n",
    "# 인덱스와 요소를 하나씩 전개하여 패딩 처리\n",
    "title_noun_vector_arr2=[]\n",
    "for index, title_noun_vector in enumerate(title_noun_vector_arr):\n",
    "    if index%1000==0:\n",
    "        print('step :', index)\n",
    "    while len(title_noun_vector)<TITLE_LENGTH:\n",
    "        title_noun_vector.append(generate_zero_noun_vector())\n",
    "    title_noun_vector=title_noun_vector[:TITLE_LENGTH]\n",
    "    title_noun_vector_arr2.append(title_noun_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 37\n"
     ]
    }
   ],
   "source": [
    "print(min_size, max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9960, 10040]\n",
      "[0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# ctr to classification\n",
    "# 클래스 개수\n",
    "NUM_CLASSES=2\n",
    "ctr_class_arr=[]\n",
    "# 클래스 개수 저장\n",
    "ctr_class_count=[0,0]\n",
    "for index, ctr in enumerate(ctr_arr):\n",
    "    if ctr==0:\n",
    "        ctr_class_arr.append(0.0)\n",
    "        ctr_class_count[0]+=1\n",
    "    elif ctr==1:\n",
    "        ctr_class_arr.append(1.0)\n",
    "        ctr_class_count[1]+=1\n",
    "print(ctr_class_count)\n",
    "print(ctr_class_arr[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 (0.0 ~ 1.0), 각 특성의 평균을 계산\n",
    "def prepare_data(arr):\n",
    "    sum1=0\n",
    "    for i in arr:\n",
    "        sum1+=i\n",
    "    arr=[float(i)/sum1 for i in arr]\n",
    "    return arr\n",
    "# 전처리가 필요한 필드에 대해 함수 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000   10000\n",
      "ctr_class_arr 개수 : 20000\n",
      "train 총 데이터 개수 : 10000\n",
      "train 라벨 개수 : 10000\n",
      "test 총 데이터 개수 : 10000\n",
      "test 라벨 개수 : 10000\n",
      "train_data_size : 10000\n",
      "test_data_size : 10000\n"
     ]
    }
   ],
   "source": [
    "# 검증용 데이터셋의 개수 구하기\n",
    "test_data_size=count_test\n",
    "train_data_size=count_train\n",
    "print(train_data_size,' ',test_data_size)\n",
    "# 학습용 데이터셋과 검증용 데이터셋을 불리하는 코드\n",
    "train_input=title_noun_vector_arr[0:train_data_size]\n",
    "train_label=ctr_class_arr[0:train_data_size]\n",
    "test_input=title_noun_vector_arr[train_data_size:]\n",
    "test_label=ctr_class_arr[train_data_size:]\n",
    "print('ctr_class_arr 개수 :', len(ctr_class_arr))\n",
    "print('train 총 데이터 개수 :', len(train_input))\n",
    "print('train 라벨 개수 :', len(train_label))\n",
    "print('test 총 데이터 개수 :', len(test_input))\n",
    "print('test 라벨 개수 :', len(test_label))\n",
    "print('train_data_size :', train_data_size)\n",
    "print('test_data_size :', test_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 케라스에 맞게 변환해주는 과정\n",
    "# 데이터 개수, 가로, 세로, 채널수(흑백이미지는 1, 컬러이미지는 3, 여기서는 텍스트이므로 1을 사용)\n",
    "# width, height, channel\n",
    "train_input=np.array(train_input)\n",
    "train_input=train_input.reshape(train_input.shape[0], train_input.shape[1], NOUN_VECTOR_SIZE, 1)\n",
    "test_input=np.array(test_input)\n",
    "test_input=test_input.reshape(test_input.shape[0], test_input.shape[1], NOUN_VECTOR_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_a=Input(shape=(train_input.shape[1], NOUN_VECTOR_SIZE, 1), name='input-layer') # 입력 데이터\n",
    "x=Conv2D(1,(3,3),  activation='relu', padding='valid', strides=(1,1))(input_a) # 첫 번째 Conv 레이어\n",
    "x=Conv2D(1,(3,3),  activation='relu')(x) # 두 번째 Conv 레이어\n",
    "x=MaxPooling2D(pool_size=(2,2))(x)\n",
    "x=Dropout(0.25)(x)\n",
    "# fully connected network\n",
    "x=Flatten()(x)\n",
    "x=Dense(128, activation='relu')(x)\n",
    "x=Dropout(0.5)(x)\n",
    "out=Dense(1, activation='sigmoid', name='output-layer')(x) # 출력 계층 (1개의 클래스로 분류됨)\n",
    "model=Model(inputs=[input_a], outputs=out) # CNN 모델이 생성됨\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) # 모델 컴파일, 손실 함수, 옵티마이저 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "30/30 [==============================] - 7s 189ms/step - loss: 1.1687 - accuracy: 0.4983 - val_loss: 0.7074 - val_accuracy: 0.5092\n",
      "Epoch 2/5\n",
      "30/30 [==============================] - 4s 118ms/step - loss: 0.7242 - accuracy: 0.5045 - val_loss: 0.6938 - val_accuracy: 0.4968\n",
      "Epoch 3/5\n",
      "30/30 [==============================] - 4s 118ms/step - loss: 0.6967 - accuracy: 0.5154 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "30/30 [==============================] - 3s 113ms/step - loss: 0.6948 - accuracy: 0.5161 - val_loss: 0.6930 - val_accuracy: 0.5012\n",
      "Epoch 5/5\n",
      "30/30 [==============================] - 3s 113ms/step - loss: 0.6948 - accuracy: 0.5068 - val_loss: 0.6936 - val_accuracy: 0.4808\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping=EarlyStopping(patience=2) # 조기 종료 콜백 함수\n",
    "hist=model.fit(x=train_input, y=np.array(train_label), validation_split=0.25, batch_size=256, epochs=5, verbose=1,\n",
    "callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5000\n",
      "loss : 69.19%\n",
      "accuracy : 50.00%\n"
     ]
    }
   ],
   "source": [
    "# 평가 \n",
    "scores=model.evaluate(np.array(test_input)[:100], np.array(test_label)[:100], batch_size=1, verbose=1)\n",
    "print(\"%s : %.2f%%\" % (model.metrics_names[0], scores[0]*100)) # 손실률\n",
    "print(\"%s : %.2f%%\" % (model.metrics_names[1], scores[1]*100)) # 정확도\n",
    "# CNN의 최종 출력값이 필요할 경우 아래 코드 사용\n",
    "m2=Model(inputs=model.input, outputs=model.get_layer('output-layer').output)\n",
    "y=m2.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49873996],\n",
       "       [0.49873996],\n",
       "       [0.5150614 ],\n",
       "       [0.49850777],\n",
       "       [0.5025537 ],\n",
       "       [0.5305687 ],\n",
       "       [0.48848504],\n",
       "       [0.517841  ],\n",
       "       [0.5062599 ],\n",
       "       [0.50747204]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: d:/data/text\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('d:/data/text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49873996]]\n",
      "1.0\n",
      "재밌군\n"
     ]
    }
   ],
   "source": [
    "n=911\n",
    "print(model.predict(np.array(train_input)[n].reshape(1, 37, 100, 1)))\n",
    "print(np.array(train_label)[n])\n",
    "print(title_arr[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5123401]]\n",
      "0.0\n",
      "OOO기 영화입니다. 긴장감도 그렇게 없고 반전도 안놀랍고 시간이 아까운 영화입니다.\n"
     ]
    }
   ],
   "source": [
    "n=5000\n",
    "print(model.predict(np.array(train_input)[n].reshape(1, 37, 100, 1)))\n",
    "print(np.array(train_label)[n])\n",
    "print(title_arr[n+10000])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b4b4feff2f24a0f0a34464dbe537a36fda679851528fb8735cb41fa49dffb2d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 통계적으로 가중치를 구한 후 두 단어 간의 유사도를 단어 간의 연관도로 적용하는 방법\n",
    "# 1. 단어마다 가중치를 할당해야 함(출현 빈도, TF-IDF 등으로 계산)\n",
    "# 2. 단어 간의 유사도 계산(cosine similarity 등의 방법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "pos_review=(glob.glob('d:/data/imdb/train/pos/*.txt'))[0:100] # 긍정 리뷰 100개 로딩\n",
    "\n",
    "lines_pos=[]\n",
    "for i in pos_review:\n",
    "    try:\n",
    "        f=open(i, 'r')\n",
    "        temp=f.readlines()[0]\n",
    "        lines_pos.append(temp)\n",
    "        f.close()\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "len(lines_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4001)\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.06538462 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.23078109 0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tokenizer=RegexpTokenizer('[\\w]+')\n",
    "stop_words=stopwords.words('english')\n",
    "# TF-IDF 가중치 할당\n",
    "vec=TfidfVectorizer(stop_words=stop_words)\n",
    "vector_lines_pos=vec.fit_transform(lines_pos)\n",
    "A=vector_lines_pos.toarray()\n",
    "print(A.shape)\n",
    "print(A)\n",
    "# x축 단어, y축 문서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4001, 100)\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.06538462 0.23078109]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 현재 상태는 100개의 문서의 유사도\n",
    "# 단어 간의 유사도를 구하는 것이 목적이므로 단어-문서 행렬로 변경\n",
    "A=A.transpose()\n",
    "\n",
    "print(A.shape)\n",
    "print(A)\n",
    "# x축 문서, y축 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.5\n",
      "  (1, 1)\t1.0\n",
      "  (2, 0)\t0.7\n",
      "  (2, 2)\t1.5\n",
      "[[0.5 0.  0. ]\n",
      " [0.  1.  0. ]\n",
      " [0.7 0.  1.5]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "# 밀집행렬(dense array)\n",
    "a=np.array([[0.5,0,0],[0,1,0],[0.7,0,1.5]])\n",
    "# 밀집행렬을 희소행렬(sparse array)로 변환\n",
    "# 밀집행렬의 단점 : 0이 많을 경우 메모리 낭비가 심함\n",
    "# 희소행렬은 0이 아닌 값들의 위치와 값만 기록하여 메모리를 절약하는 방식\n",
    "b=sparse.csr_matrix(a)\n",
    "print(b)\n",
    "# (0, 0) 0.5 → 인덱스 0,0에 값 0.5\n",
    "# (1, 1) 1.0 → 인덱스 1,1에 값 1.0\n",
    "# (2, 0) 0.7 → 인덱스 2,0에 값 0.7\n",
    "# (2, 2) 1.5 → 인덱스 2,2에 값 1.5\n",
    "c=b.toarray()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1469, 108), 0.37803585968894865),\n",
       " ((1470, 108), 0.2189685434746738),\n",
       " ((1476, 108), 0.06407477897013734),\n",
       " ((1477, 108), 0.185189577514238),\n",
       " ((1480, 108), 0.20111036876169444),\n",
       " ((1489, 108), 0.06995711757772019),\n",
       " ((1496, 108), 0.10714874067068783),\n",
       " ((1503, 108), 0.30487333830091773),\n",
       " ((1504, 108), 0.30487333830091773),\n",
       " ((1512, 108), 0.30487333830091773)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "A_sparse=sparse.csr_matrix(A)\n",
    "similarities_sparse=cosine_similarity(A_sparse, dense_output=False) # 코사인 유사도 계산\n",
    "list(similarities_sparse.todok().items())[35000:35010] # todok() : 행렬을 딕셔너리 형태로 변환\n",
    "\n",
    "# 단어 이름이 아닌 인덱스 형태로 출력\n",
    "# ((1469, 108), 0.37803585968894865) → 1469 단어와 108 단어의 유사도는 37%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraud\n",
      "actual\n"
     ]
    }
   ],
   "source": [
    "print(vec.get_feature_names()[1469])\n",
    "print(vec.get_feature_names()[108])\n",
    "# fraud와 actual의 유사도는 37.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(3971, 3372)</td>\n",
       "      <td>0.499961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(3372, 3971)</td>\n",
       "      <td>0.499961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1192, 2554)</td>\n",
       "      <td>0.499958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(2554, 1192)</td>\n",
       "      <td>0.499958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(2468, 1321)</td>\n",
       "      <td>0.499957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(2468, 710)</td>\n",
       "      <td>0.499957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(710, 2468)</td>\n",
       "      <td>0.499957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1321, 2468)</td>\n",
       "      <td>0.499957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(2146, 889)</td>\n",
       "      <td>0.499909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(889, 2146)</td>\n",
       "      <td>0.499909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          words    weight\n",
       "0  (3971, 3372)  0.499961\n",
       "1  (3372, 3971)  0.499961\n",
       "2  (1192, 2554)  0.499958\n",
       "3  (2554, 1192)  0.499958\n",
       "4  (2468, 1321)  0.499957\n",
       "5   (2468, 710)  0.499957\n",
       "6   (710, 2468)  0.499957\n",
       "7  (1321, 2468)  0.499957\n",
       "8   (2146, 889)  0.499909\n",
       "9   (889, 2146)  0.499909"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 위의 결과값을 데이터프레임으로 출력\n",
    "df=pd.DataFrame(list(similarities_sparse.todok().items()), columns=['words','weight'])\n",
    "df2=df.sort_values(by=['weight'], ascending=False)\n",
    "df2=df2.reset_index(drop=True)\n",
    "df3=df2.loc[np.round(df2['weight'])<1] # 자기 자신과의 짝은 1이 되므로 1 미만의 항목들만 출력\n",
    "df3=df3.reset_index(drop=True)\n",
    "df3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writers\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "print(vec.get_feature_names()[3971])\n",
    "print(vec.get_feature_names()[3372])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b4b4feff2f24a0f0a34464dbe537a36fda679851528fb8735cb41fa49dffb2d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
